combModel<-train(diagnosis~., method="rf", data=predDF)
combPred<-predict(combModel, testing)
c1<- confusionMatrix(pred1, testing$diagnosis)
c1
c2<- confusionMatrix(pred2, testing$diagnosis)
c2
c3<- confusionMatrix(pred3, testing$diagnosis)
c3
c4<- confusionMatrix(combPred, testing$diagnosis)
c4
stack.test2 <- predict(stack.fit, testing)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rf.fit <- train(diagnosis ~., method = "rf", data = training)
gbm.fit <- train(diagnosis ~., method = "gbm", data = training)
lda.fit <- train(diagnosis ~., method = "lda", data = training)
rf.test <- predict(rf.fit, testing)
confusionMatrix(testing$diagnosis, rf.test)
gbm.test <- predict(gbm.fit, testing)
confusionMatrix(testing$diagnosis, gbm.test)
lda.test<- predict(lda.fit, testing)
confusionMatrix(testing$diagnosis, lda.test)
stack.data <-data.frame(rf.test, gbm.test, lda.test, diagnosis = testing$diagnosis)
stack.fit <- train(diagnosis ~., method = "rf", stack.data)
stack.test <- predict(stack.fit, stack.data)
confusionMatrix(testing$diagnosis, stack.test)
stack.test2 <- predict(stack.fit, testing)
confusionMatrix(testing$diagnosis, stack.test2)
stack.test3 <- predict(stack.fit, training)
stack.test2 <- predict(stack.fit, testing)
compare(stack.test, stack.test2)
data.fraime(stack.test, stack.test2)
data.frame(stack.test, stack.test2)
rm(list = ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
?plot.enet
set.seed(233)
str(training)
fit <- train(CompressiveStrength ~ ., data = training, method = "lasso")
?plot.enet
plot(fit)
plot.enet(fit)
plot.enet(fit$finalModel, xvar = "penalty", use.color = TRUE)
?plot.enet
library(lubridate)  # For year() function below
dat = read.csv("C:/Users/sean.huang/Desktop/Downloads/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
str(Dat)
str(dat)
View(dat)
dat$date[1,]
dat$date[1]
year(dat$date[1])
tstrain
tstest<- predict(tstrain, testing)
?bat()
?bats()
library(forecast)
?bats()
tstrain
str(tstrain)
ts.fit<- bats(tstrain)
plot(forcast(ts.fit))
plot(forecast(ts.fit))
accuracy(ts.fit,test$visitsTumblr)
accuracy(forecast(ts.fit),test$visitsTumblr)
accuracy(forecast(ts.fit),testing$visitsTumblr)
?forecast
plot(ts.fit)
h<- dim(testing)[1]
h
accuracy(forecast(ts.fit, h, level = 95),testing$visitsTumblr)
plot(forecast(ts.fit, h, level = 95))
accuracy(forecast(ts.fit, h, level = 95),testing$visitsTumblr)
predict <- forecast(ts.fit, h, level = 95)
str(predict)
predict
lenghth(predict)
length(predict)
length(predict)
str(predict)
predict$Forecast
length(predict$Forecast)
length(predict.Forecast)
predict.Forecast
predict@Forecast
predict
predict(lower)
predict$lower
fcast <- forecast(ts.fit, h, level = 95)
result <- c()
l <- length(fcast$lower)
for (i in 1:l){
x <- testing$visitsTumblr[i]
a <- fcast$lower[i] < x & x < fcast$upper[i]
result <- c(result, a)
}
sum(result)/l * 100
result
h
rm(list = ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(e1071)
svm.Fit <- svm(CompressiveStrength ~ ., data = training)
svm.p <- predict(svm.Fit, testing)
confusionMatrix(testing$CompressiveStrength, svm.p)
svm.p
testing$CompressiveStrength
svm.p <- predict(svm.Fit, testing[,-CompressiveStrength])
str(testing)
svm.p <- predict(svm.Fit, testing[,-9])
confusionMatrix(testing$CompressiveStrength, svm.p)
svm.p
svm.p <- predict(svm.Fit, newdata = testing[,-9])
svm.p
svm.Fit <- svm(CompressiveStrength ~ ., data = training)
rm(list = ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
svm.Fit <- svm(CompressiveStrength ~ ., data = training)
svm.p <- predict(svm.Fit, newdata = testing[,-9])
confusionMatrix(testing$CompressiveStrength, svm.p)
svm.p
str(svm.p)
testing$CompressiveStrength
accuracy(testing$CompressiveStrength, svm.p)
log(1)
log(0)
log(2)
2^0.6931472
10^0.6931472
log(10)
log(100)
log10(100)
1.6*0.6931472
e
?greo
?grep
?preProcess
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
rm(list = ls())
############################################
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
View(segmentationOriginal)
str(segmentationOriginal)
train <- segmentationOriginal[,Case == "Train"]
train <- segmentationOriginal[, segmentationOriginal$Case == "Train"]
train <- segmentationOriginal[, segmentationOriginal$Case == "Train"]
train <- segmentationOriginal[segmentationOriginal$Case == "Train", ]
test <- subset(setmentationOriginal, Case == "Test")
test <- subset(segmentationOriginal, Case == "Test")
cart.fit <- train(Class ~., method = "rpart", train)
cart.fit$finalModel
plot(cart.fit)
plot(cart.fit$finalModel, uniform = TRUE, main = "Classification Tree")
fancyRpartPlot(cart.fit$finalModel)
install.packages(rattle)
install.packages("rattle")
library(rpart)
fancyRpartPlot(cart.fit$finalModel)
library(rattle)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
library(rpart)
library(rattle)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
library(rpart)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
library(rpart)
library(rattle)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
library(rpart)
library(rattle)
remove.packages("rattle")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
library(rpart)
library(rattle)
install.packages("rattle")
library(rattle)
install.packages("GTK+")
remove.packages("GTK+")
install.packages(GTK+)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
library(rpart)
library(rattle)
library(rattle)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
library(caret)
View(testSA)
logi.fit <- train(chd ~., trainSA, method = "glm", family="binomial")
logi.fit <- train(chd~age+alcohol+obesity+tobacco+typea+ldl, trainSA, method = "glm", family = "binomial")
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(trainSA$chd, predict(logi.fit, trainSA))
rm(lst = ls())
rm(list = ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
library(caret)
View(vowel.test)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
?caret
?train
?rf
rf.fit = train(y ~., vowel.train, method = "rf", importance = FALSE )
varImp(rf.fit)
rf.fit2 = train(y ~., vowel.train, method = "rf")
importance(rf.fit2)
importance(rf.fit2)
rf.fit2
str(rf.fit2)
rf.fit2$coefnames
rf.fit2$xlevels
rf.fit2$results
rf.fit2$perfNames
imp(rf.fit2)
rf.fit2$importance
varImp(rf.fit2)
varImp(rf.fit)
rf.fit2[importance]
rf.fit2[[importance]]
install.packages("shiny")
library(shiny)
install.packages("usingR")
install.packages("UsingR")
install.packages("rChart")
install.packages("rCharts")
require(rCharts)
install.packages("googleVis")
install.packages("devtools")
devtools::install_github("rstudio/shinyapps")
devtools::install_github('rstudio/shinyapps')
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='eg7649', token='3EF15596496899ED454D590DF5BB16A2', secret='/VtDtgv+c/hb15HVj2S7+N3I1YXusHrVAqyjNNEX')
library(shinyapps)
shinyapps::setAccountInfo(name='eg7649', token='3EF15596496899ED454D590DF5BB16A2', secret='/VtDtgv+c/hb15HVj2S7+N3I1YXusHrVAqyjNNEX')
library(manipulate)
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
View(myPlot)
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
install.packages('rCharts')
install_github(’rCharts’)
install_github('rCharts')
require(devtools)
install_github('rCharts')
install_github(’rCharts’, ’ramnathv’)
install_github(’rCharts’, 'ramnathv')
install_github('rCharts', 'ramnathv')
require(rCharts)
library(rCharts)
?ptable
?dTable
library(shiny)
library(shinyapps)
library(manipulate)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h3('Sidebar')
),
mainPanel(
h3('Main Panel text')
)
))
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h3('Sidebar')
),
mainPanel(
h3('Main Panel text')
),
))
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h3('Sidebar')
),
mainPanel(
h3('Main Panel text')
),
)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h3('Sidebar text')
),
mainPanel(
h3('Main Panel text')
)
))
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h3('Sidebar text')
),
mainPanel(
h3('Main Panel text')
)
))
shinyServer(
funtion(input, output){
}
)
rm(list= ls())
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h3('Sidebar text')
),
mainPanel(
h3('Main Panel text')
)
))
shinyServer(
funtion(input, output){
}
)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('Big text')
h3('Sidebar text')
),
mainPanel(
h3('Main Panel text')
)
))
shinyServer(
funtion(input, output){
}
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h2('sidebar text')
h3('Sidebar text')
),
mainPanel(
h3('Main Panel text')
)
))
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h3('Sidebar text')
),
mainPanel(
h3('Main Panel text')
)
))
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h3('sidebar text')
h3('Sidebar text')
),
mainPanel(
h3('Main Panel text')
)
))
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h3('sidebar text')
),
mainPanel(
h3('Main Panel text')
)
))
library(shiny)
shinyServer(
function(input, output) {
}
)
library(manipulate)
myHist <- function(mu){
hist(galton$child,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
library(manipulate)
data(galton)
myHist <- function(mu){
hist(galton$child,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
data(galton)
data(Galton)
data(Galton)
library(UsingR)
data(galton)
View(myHist)
myHist <- function(mu){
hist(galton$child,col="blue",breaks=100)
lines(c(mu, mu), c(0, 150),col="red",lwd=5)
mse <- mean((galton$child - mu)^2)
text(63, 150, paste("mu = ", mu))
text(63, 140, paste("MSE = ", round(mse, 2)))
}
manipulate(myHist(mu), mu = slider(62, 74, step = 0.5))
require(rCharts)
haireye = as.data.frame(HairEyeColor)
n1 <- nPlot(Freq ~ hair, group = "Eye", type = "multiBarChart",
data = subset(haireye, Sex == "Male")
)
require(rCharts)
haireye = as.data.frame(HairEyeColor)
n1 <- nPlot(Freq ~ Hair, group = "Eye", type = "multiBarChart",
data = subset(haireye, Sex == "Male")
)
n1$save("fig/n1.html", cdn = TRUE)
install.packages()
install.packages("googleVis")
suppressPackageStartupMessages(library(googleVis))
a
G <- gvisGeoChart(Exports, locationvar = "Country", colorvar = "Profit", options = list(width =height = 400))
M <- gvisMotionChart(Fruits, "Fruit", "Year", options = list(width = 600, height = 400))
print(M, "chart")
G <- gvisGeoChart(Exports, locationvar = "Country", colorvar = "Profit", options = list(width =height = 400))
G <- gvisGeoChart(Exports, locationvar = "Country", colorvar = "Profit", options = list(width =600, height = 400))
print(G, "chart")
setwd("D:/Sean Huang/My Program files/RSpace/developingDataProducts")
data <- read.csv("data/knowledge.csv")
shiny::runApp()
publish(user = "ys-huang", repo = "dataProducts_pitch")
install.packages("git")
publish_github(dataProducts_pitch, username = getOption("ys-huang"))
library(slidify)
publish(user = "ys-huang", repo = "dataProducts_pitch")
publish(user = "ys-huang", repo = "dataProducts_pitch")
publish(user = "ys-huang", repo = "dataProducts_pitch")
publish_github(dataProducts_pitch, username = getOption("ys-huang"))
publish_github(dataProducts_pitch, username = getOption("ys-huang"))
setwd("D:/Sean Huang/My Program files/RSpace/slidify/dataproducts_pitch")
publish_github(dataProducts_pitch, username = getOption("ys-huang"))
publish(user = "ys-huang", repo = "dataProducts_pitch")
